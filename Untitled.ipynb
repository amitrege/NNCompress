{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "joOw-YmN8Cse",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install Importance Sampling module for Keras"
      ]
    },
    {
      "metadata": {
        "id": "uZEGRscE8Csg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "feafef24-d96e-44f1-a4c7-ac9e2b610013"
      },
      "cell_type": "code",
      "source": [
        "# Install Dependency\n",
        "!pip3 install blinker\n",
        "\n",
        "# Clone Repo\n",
        "!pip install --user keras-importance-sampling\n",
        "!git clone https://github.com/idiap/importance-sampling.git\n",
        "  \n",
        "# Convert the repo into a module for usage in the notebook\n",
        "!touch importance-sampling/__init__.py\n",
        "!touch importance-sampling/importance_sampling/__init__.py\n",
        "!touch importance-sampling/examples/__init__.py\n",
        "!cp -r importance-sampling/* .\n",
        "\n",
        "# Copy contents of repo for easy usage \n",
        "!cp -r importance-sampling/* ."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: blinker in /usr/local/lib/python3.6/dist-packages (1.4)\n",
            "Requirement already satisfied: keras-importance-sampling in /root/.local/lib/python3.6/site-packages (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-importance-sampling) (1.16.3)\n",
            "Requirement already satisfied: keras>=2 in /usr/local/lib/python3.6/dist-packages (from keras-importance-sampling) (2.2.4)\n",
            "Requirement already satisfied: blinker in /usr/local/lib/python3.6/dist-packages (from keras-importance-sampling) (1.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2->keras-importance-sampling) (1.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2->keras-importance-sampling) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2->keras-importance-sampling) (1.2.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2->keras-importance-sampling) (1.0.7)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2->keras-importance-sampling) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2->keras-importance-sampling) (3.13)\n",
            "fatal: destination path 'importance-sampling' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m_ust0uV8vCL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ]
    },
    {
      "metadata": {
        "id": "z58Zrtou8sFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f657bed0-90db-4e13-9efc-b8b754aaf7bd"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.callbacks import LearningRateScheduler, Callback\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers import Activation, BatchNormalization, Conv2D, Dense, \\\n",
        "    GlobalAveragePooling2D, Input, add\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "\n",
        "from importance_sampling.datasets import CIFAR10, ZCAWhitening\n",
        "from importance_sampling.models import wide_resnet\n",
        "from importance_sampling.training import ImportanceTraining\n",
        "from examples.example_utils import get_parser\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e3VVra8hCrsK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Wide Resnet Baseline on CIFAR 10"
      ]
    },
    {
      "metadata": {
        "id": "GJijzuQ2MSj_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper Classes"
      ]
    },
    {
      "metadata": {
        "id": "UAPZuCmUCr2u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TrainingSchedule(Callback):\n",
        "    \"\"\"Implement the training schedule for training a resnet on CIFAR10 for a\n",
        "    given time budget.\"\"\"\n",
        "    def __init__(self, total_time):\n",
        "        self._total_time = total_time\n",
        "        self._lr = self._get_lr(0.0)\n",
        "\n",
        "    def _get_lr(self, progress):\n",
        "        if progress > 0.8:\n",
        "            return 0.004\n",
        "        elif progress > 0.5:\n",
        "            return 0.02\n",
        "        else:\n",
        "            return 0.1\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self._start = time.time()\n",
        "        self._lr = self._get_lr(0.0)\n",
        "        K.set_value(self.model.optimizer.lr, self._lr)\n",
        "\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        t = time.time() - self._start\n",
        "\n",
        "        if t >= self._total_time:\n",
        "            self.model.stop_training = True\n",
        "\n",
        "        lr = self._get_lr(t / self._total_time)\n",
        "        if lr != self._lr:\n",
        "            self._lr = lr\n",
        "            K.set_value(self.model.optimizer.lr, self._lr)\n",
        "\n",
        "    @property\n",
        "    def lr(self):\n",
        "        return self._lr\n",
        "\n",
        "class Args():\n",
        "  def __init__(self, depth, width, presample, batch_size, time_budget, dropout, useIS):\n",
        "    self.depth = depth\n",
        "    self.width = width\n",
        "    self.presample = presample\n",
        "    self.batch_size = batch_size\n",
        "    self.time_budget = 3600*time_budget\n",
        "    self.dropout = dropout\n",
        "    self.importance_training = useIS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zru-xiiuMY9R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "metadata": {
        "id": "JVveTrnSMKdt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "dset = ZCAWhitening(CIFAR10())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_sCpBbm5VvkA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Utility Functions"
      ]
    },
    {
      "metadata": {
        "id": "7M6BTAvxOEFo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build Model"
      ]
    },
    {
      "metadata": {
        "id": "8i41c8AIMsLt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model(args, dset):\n",
        "  training_schedule = TrainingSchedule(args.time_budget)\n",
        "  model = wide_resnet(args.depth, args.width, args.dropout)(dset.shape, dset.output_size)\n",
        "  model.compile(\n",
        "      loss=\"categorical_crossentropy\",\n",
        "      optimizer=SGD(lr=training_schedule.lr, momentum=0.9),\n",
        "      metrics=[\"accuracy\"]\n",
        "  )\n",
        "  model.summary()\n",
        "  return model, training_schedule"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GiG6DsuQOYUV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ]
    },
    {
      "metadata": {
        "id": "21CtI5KmObaC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model, args, x_train, y_train, x_test, y_test, training_schedule):\n",
        "  # Create the data augmentation generator\n",
        "  datagen = ImageDataGenerator(\n",
        "      # set input mean to 0 over the dataset\n",
        "      featurewise_center=False,\n",
        "      # set each sample mean to 0\n",
        "      samplewise_center=False,\n",
        "      # divide inputs by std of dataset\n",
        "      featurewise_std_normalization=False,\n",
        "      # divide each input by its std\n",
        "      samplewise_std_normalization=False,\n",
        "      # apply ZCA whitening\n",
        "      zca_whitening=False,\n",
        "      # randomly rotate images in the range (deg 0 to 180)\n",
        "      rotation_range=0,\n",
        "      # randomly shift images horizontally\n",
        "      width_shift_range=0.1,\n",
        "      # randomly shift images vertically\n",
        "      height_shift_range=0.1,\n",
        "      # randomly flip images\n",
        "      horizontal_flip=True,\n",
        "      # randomly flip images\n",
        "      vertical_flip=False)\n",
        "  datagen.fit(x_train)\n",
        "\n",
        "  # Train the model\n",
        "  if args.importance_training:\n",
        "      history = ImportanceTraining(model).fit_generator(\n",
        "          datagen.flow(x_train, y_train, batch_size=args.batch_size),\n",
        "          validation_data=(x_test, y_test),\n",
        "          epochs=10**6,\n",
        "          verbose=1,\n",
        "          callbacks=[training_schedule],\n",
        "          batch_size=args.batch_size,\n",
        "          steps_per_epoch=int(np.ceil(float(len(x_train)) / args.batch_size))\n",
        "      )\n",
        "  else:\n",
        "      history = model.fit_generator(\n",
        "          datagen.flow(x_train, y_train, batch_size=args.batch_size),\n",
        "          validation_data=(x_test, y_test),\n",
        "          epochs=10**6,\n",
        "          verbose=1,\n",
        "          callbacks=[training_schedule]\n",
        "      )\n",
        "  return model, history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GCe1uH3GOjQH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "metadata": {
        "id": "TxCKGW-7Ok-q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Score trained model.\n",
        "def eval_model(model, x_test, y_test):\n",
        "  scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "  print('Test loss:', scores[0])\n",
        "  print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m92bo7ljVerh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Wrapper "
      ]
    },
    {
      "metadata": {
        "id": "rxWcImXNVlxb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_wide_res(args, dset):\n",
        "  # Split dataset\n",
        "  x_train, y_train = dset.train_data[:]\n",
        "  x_test, y_test = dset.test_data[:]\n",
        "\n",
        "  model, training_schedule = build_model(args, dset)\n",
        "  model, history = train_model(model, args, x_train, y_train, x_test, y_test, training_schedule)\n",
        "  return model, history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2BvpR1UJHfq4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Saving the model and plots to Drive"
      ]
    },
    {
      "metadata": {
        "id": "YB6PgaYPHfC0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_model(model, file_name):\n",
        "  path = \"gdrive/My Drive/\"\n",
        "  model.save(path + file_name + '.h5')\n",
        "  \n",
        "def save_plots(model, history, file_name):\n",
        "  path = \"gdrive/My Drive\" + file_name\n",
        "  \n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['accuracy'][:-1])\n",
        "  plt.plot(history.history['val_accuracy'][:-1])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.savefig(path + \"-acc.png\")\n",
        "  plt.show()\n",
        "\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'][:-1])\n",
        "  plt.plot(history.history['val_loss'][:-1])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.savefig(path + \"-loss.png\")\n",
        "  plt.show()\n",
        "  \n",
        "def save(model, history, file_name):\n",
        "  save_model(model, file_name)\n",
        "  save_plots(model, histiry, file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lw1Sc9PBWqQY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "ZHiDk__Wa4r6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Wide ResNet 28-2 with 0.3 dropout and max time of 1 hr (with IS)"
      ]
    },
    {
      "metadata": {
        "id": "xBLZkasYWpP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5885
        },
        "outputId": "1e622acf-a9dc-4bd3-c1fe-c2c7d68c7bda"
      },
      "cell_type": "code",
      "source": [
        "args = Args(depth = 28, width = 2, presample = 3.0, batch_size = 128, time_budget = 1, dropout = 0.3, useIS = True)\n",
        "model, history = build_wide_res(args, dset)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 32, 32, 16)   432         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_51 (LayerNo (None, 32, 32, 16)   17          conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 32, 32, 16)   0           layer_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 32, 32, 32)   4608        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 32)   0           conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_52 (LayerNo (None, 32, 32, 32)   33          dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 32, 32, 32)   0           layer_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 32, 32, 32)   512         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 32, 32, 32)   9216        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 32, 32, 32)   0           conv2d_60[0][0]                  \n",
            "                                                                 conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_53 (LayerNo (None, 32, 32, 32)   33          add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 32, 32, 32)   0           layer_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 32, 32, 32)   9216        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 32)   0           conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_54 (LayerNo (None, 32, 32, 32)   33          dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 32, 32, 32)   0           layer_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 32, 32, 32)   9216        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 32, 32, 32)   0           add_25[0][0]                     \n",
            "                                                                 conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_55 (LayerNo (None, 32, 32, 32)   33          add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 32, 32, 32)   0           layer_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 32, 32, 32)   9216        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 32)   0           conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_56 (LayerNo (None, 32, 32, 32)   33          dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 32, 32, 32)   0           layer_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 32, 32, 32)   9216        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 32, 32, 32)   0           add_26[0][0]                     \n",
            "                                                                 conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_57 (LayerNo (None, 32, 32, 32)   33          add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 32, 32, 32)   0           layer_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 32, 32, 32)   9216        activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 32)   0           conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_58 (LayerNo (None, 32, 32, 32)   33          dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 32, 32, 32)   0           layer_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 32, 32, 32)   9216        activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 32, 32, 32)   0           add_27[0][0]                     \n",
            "                                                                 conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_59 (LayerNo (None, 32, 32, 32)   33          add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 32, 32, 32)   0           layer_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 16, 16, 64)   18432       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 16, 16, 64)   0           conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_60 (LayerNo (None, 16, 16, 64)   65          dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 64)   0           layer_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 16, 16, 64)   2048        add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 16, 16, 64)   36864       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 16, 16, 64)   0           conv2d_69[0][0]                  \n",
            "                                                                 conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_61 (LayerNo (None, 16, 16, 64)   65          add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 64)   0           layer_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 16, 16, 64)   36864       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 16, 16, 64)   0           conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_62 (LayerNo (None, 16, 16, 64)   65          dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 16, 16, 64)   0           layer_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 16, 16, 64)   36864       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 16, 16, 64)   0           add_29[0][0]                     \n",
            "                                                                 conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_63 (LayerNo (None, 16, 16, 64)   65          add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 16, 16, 64)   0           layer_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 16, 16, 64)   36864       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 16, 16, 64)   0           conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_64 (LayerNo (None, 16, 16, 64)   65          dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 16, 16, 64)   0           layer_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 16, 16, 64)   36864       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 16, 16, 64)   0           add_30[0][0]                     \n",
            "                                                                 conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_65 (LayerNo (None, 16, 16, 64)   65          add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 16, 16, 64)   0           layer_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 16, 16, 64)   36864       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 16, 16, 64)   0           conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_66 (LayerNo (None, 16, 16, 64)   65          dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 16, 16, 64)   0           layer_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 16, 16, 64)   36864       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 16, 16, 64)   0           add_31[0][0]                     \n",
            "                                                                 conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_67 (LayerNo (None, 16, 16, 64)   65          add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 16, 16, 64)   0           layer_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 128)    73728       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 8, 8, 128)    0           conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_68 (LayerNo (None, 8, 8, 128)    129         dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 8, 8, 128)    0           layer_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 128)    8192        add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 128)    147456      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 8, 8, 128)    0           conv2d_78[0][0]                  \n",
            "                                                                 conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_69 (LayerNo (None, 8, 8, 128)    129         add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 128)    0           layer_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 128)    147456      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 8, 8, 128)    0           conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_70 (LayerNo (None, 8, 8, 128)    129         dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 128)    0           layer_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 128)    147456      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 8, 8, 128)    0           add_33[0][0]                     \n",
            "                                                                 conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_71 (LayerNo (None, 8, 8, 128)    129         add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 8, 8, 128)    0           layer_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 128)    147456      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 8, 8, 128)    0           conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_72 (LayerNo (None, 8, 8, 128)    129         dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 8, 8, 128)    0           layer_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 128)    147456      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 8, 8, 128)    0           add_34[0][0]                     \n",
            "                                                                 conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_73 (LayerNo (None, 8, 8, 128)    129         add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 128)    0           layer_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 128)    147456      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 8, 8, 128)    0           conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_74 (LayerNo (None, 8, 8, 128)    129         dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 128)    0           layer_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 128)    147456      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 8, 8, 128)    0           add_35[0][0]                     \n",
            "                                                                 conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_75 (LayerNo (None, 8, 8, 128)    129         add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 128)    0           layer_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 128)          0           activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           1290        global_average_pooling2d_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 10)           0           dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,465,827\n",
            "Trainable params: 1,465,827\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[NOTICE]: You are using BatchNormalization and/or Dropout.\n",
            "Those layers may affect the importance calculations and you are advised to exchange them for LayerNormalization or BatchNormalization in test mode and L2 regularization.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000000\n",
            "391/391 [==============================] - 66s 169ms/step - loss: 2.8861 - accuracy: 0.1307 - val_loss: 2.0511 - val_accuracy: 0.2047\n",
            "Epoch 2/1000000\n",
            "391/391 [==============================] - 62s 160ms/step - loss: 2.1761 - accuracy: 0.2905 - val_loss: 1.7186 - val_accuracy: 0.3592\n",
            "Epoch 3/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.8170 - accuracy: 0.3983 - val_loss: 1.6386 - val_accuracy: 0.4000\n",
            "Epoch 4/1000000\n",
            "391/391 [==============================] - 63s 161ms/step - loss: 1.6575 - accuracy: 0.4520 - val_loss: 1.5467 - val_accuracy: 0.4576\n",
            "Epoch 5/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.5172 - accuracy: 0.5099 - val_loss: 1.3598 - val_accuracy: 0.5327\n",
            "Epoch 6/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.3906 - accuracy: 0.5681 - val_loss: 1.3749 - val_accuracy: 0.5273\n",
            "Epoch 7/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.3572 - accuracy: 0.5880 - val_loss: 0.9828 - val_accuracy: 0.6477\n",
            "Epoch 8/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.3044 - accuracy: 0.6136 - val_loss: 1.0989 - val_accuracy: 0.6256\n",
            "Epoch 9/1000000\n",
            "391/391 [==============================] - 63s 161ms/step - loss: 1.2779 - accuracy: 0.6318 - val_loss: 1.1104 - val_accuracy: 0.6181\n",
            "Epoch 10/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.2464 - accuracy: 0.6468 - val_loss: 0.9429 - val_accuracy: 0.6736\n",
            "Epoch 11/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.2183 - accuracy: 0.6635 - val_loss: 0.9352 - val_accuracy: 0.6725\n",
            "Epoch 12/1000000\n",
            "391/391 [==============================] - 62s 160ms/step - loss: 1.1828 - accuracy: 0.6833 - val_loss: 0.9207 - val_accuracy: 0.6837\n",
            "Epoch 13/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.1774 - accuracy: 0.6923 - val_loss: 0.8790 - val_accuracy: 0.6897\n",
            "Epoch 14/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.1429 - accuracy: 0.7104 - val_loss: 0.8817 - val_accuracy: 0.7002\n",
            "Epoch 15/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.1189 - accuracy: 0.7249 - val_loss: 0.7760 - val_accuracy: 0.7324\n",
            "Epoch 16/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.1133 - accuracy: 0.7329 - val_loss: 0.8793 - val_accuracy: 0.7038\n",
            "Epoch 17/1000000\n",
            "391/391 [==============================] - 62s 160ms/step - loss: 1.1033 - accuracy: 0.7394 - val_loss: 0.9217 - val_accuracy: 0.6916\n",
            "Epoch 18/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.0906 - accuracy: 0.7485 - val_loss: 0.7690 - val_accuracy: 0.7419\n",
            "Epoch 19/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.0780 - accuracy: 0.7518 - val_loss: 0.6221 - val_accuracy: 0.7876\n",
            "Epoch 20/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.0631 - accuracy: 0.7598 - val_loss: 0.7733 - val_accuracy: 0.7373\n",
            "Epoch 21/1000000\n",
            "391/391 [==============================] - 62s 160ms/step - loss: 1.0789 - accuracy: 0.7579 - val_loss: 0.7212 - val_accuracy: 0.7570\n",
            "Epoch 22/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.0553 - accuracy: 0.7668 - val_loss: 0.6819 - val_accuracy: 0.7723\n",
            "Epoch 23/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.0530 - accuracy: 0.7715 - val_loss: 0.6576 - val_accuracy: 0.7745\n",
            "Epoch 24/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.0611 - accuracy: 0.7693 - val_loss: 0.6057 - val_accuracy: 0.7897\n",
            "Epoch 25/1000000\n",
            "391/391 [==============================] - 62s 160ms/step - loss: 1.0672 - accuracy: 0.7691 - val_loss: 0.6870 - val_accuracy: 0.7730\n",
            "Epoch 26/1000000\n",
            "391/391 [==============================] - 62s 159ms/step - loss: 1.0629 - accuracy: 0.7732 - val_loss: 0.6121 - val_accuracy: 0.7850\n",
            "Epoch 27/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.0519 - accuracy: 0.7755 - val_loss: 0.6911 - val_accuracy: 0.7632\n",
            "Epoch 28/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.0575 - accuracy: 0.7755 - val_loss: 0.6562 - val_accuracy: 0.7761\n",
            "Epoch 29/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 1.0258 - accuracy: 0.7849 - val_loss: 0.4702 - val_accuracy: 0.8396\n",
            "Epoch 30/1000000\n",
            "391/391 [==============================] - 62s 160ms/step - loss: 0.7974 - accuracy: 0.8539 - val_loss: 0.4353 - val_accuracy: 0.8545\n",
            "Epoch 31/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 0.7346 - accuracy: 0.8610 - val_loss: 0.4008 - val_accuracy: 0.8646\n",
            "Epoch 32/1000000\n",
            "391/391 [==============================] - 62s 160ms/step - loss: 0.6891 - accuracy: 0.8667 - val_loss: 0.4318 - val_accuracy: 0.8524\n",
            "Epoch 33/1000000\n",
            "391/391 [==============================] - 63s 161ms/step - loss: 0.6667 - accuracy: 0.8662 - val_loss: 0.4110 - val_accuracy: 0.8616\n",
            "Epoch 34/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 0.6455 - accuracy: 0.8676 - val_loss: 0.4439 - val_accuracy: 0.8520\n",
            "Epoch 35/1000000\n",
            "391/391 [==============================] - 62s 160ms/step - loss: 0.6352 - accuracy: 0.8675 - val_loss: 0.4111 - val_accuracy: 0.8623\n",
            "Epoch 36/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 0.6298 - accuracy: 0.8665 - val_loss: 0.4100 - val_accuracy: 0.8611\n",
            "Epoch 37/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 0.6209 - accuracy: 0.8676 - val_loss: 0.4661 - val_accuracy: 0.8438\n",
            "Epoch 38/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 0.6130 - accuracy: 0.8697 - val_loss: 0.4809 - val_accuracy: 0.8421\n",
            "Epoch 39/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 0.6134 - accuracy: 0.8701 - val_loss: 0.4387 - val_accuracy: 0.8529\n",
            "Epoch 40/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 0.6169 - accuracy: 0.8673 - val_loss: 0.4459 - val_accuracy: 0.8483\n",
            "Epoch 41/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 0.6076 - accuracy: 0.8713 - val_loss: 0.4133 - val_accuracy: 0.8562\n",
            "Epoch 42/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 0.6073 - accuracy: 0.8714 - val_loss: 0.4525 - val_accuracy: 0.8487\n",
            "Epoch 43/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 0.6141 - accuracy: 0.8715 - val_loss: 0.3971 - val_accuracy: 0.8664\n",
            "Epoch 44/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 0.6059 - accuracy: 0.8715 - val_loss: 0.4410 - val_accuracy: 0.8522\n",
            "Epoch 45/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 0.6046 - accuracy: 0.8749 - val_loss: 0.4008 - val_accuracy: 0.8679\n",
            "Epoch 46/1000000\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 0.6133 - accuracy: 0.8730 - val_loss: 0.3958 - val_accuracy: 0.8649\n",
            "Epoch 47/1000000\n",
            "391/391 [==============================] - 93s 237ms/step - loss: 0.4791 - accuracy: 0.5550 - val_loss: 0.3228 - val_accuracy: 0.8965\n",
            "Epoch 48/1000000\n",
            "391/391 [==============================] - 96s 246ms/step - loss: 0.4470 - accuracy: 0.5138 - val_loss: 0.3079 - val_accuracy: 0.9002\n",
            "Epoch 49/1000000\n",
            "391/391 [==============================] - 96s 246ms/step - loss: 0.4265 - accuracy: 0.5218 - val_loss: 0.3156 - val_accuracy: 0.9003\n",
            "Epoch 50/1000000\n",
            "391/391 [==============================] - 96s 246ms/step - loss: 0.4156 - accuracy: 0.5295 - val_loss: 0.3136 - val_accuracy: 0.8978\n",
            "Epoch 51/1000000\n",
            "391/391 [==============================] - 96s 245ms/step - loss: 0.4104 - accuracy: 0.5297 - val_loss: 0.3117 - val_accuracy: 0.9000\n",
            "Epoch 52/1000000\n",
            "391/391 [==============================] - 95s 244ms/step - loss: 0.3863 - accuracy: 0.5458 - val_loss: 0.3142 - val_accuracy: 0.9000\n",
            "Epoch 53/1000000\n",
            "391/391 [==============================] - 96s 244ms/step - loss: 0.3782 - accuracy: 0.5493 - val_loss: 0.3072 - val_accuracy: 0.9034\n",
            "Epoch 54/1000000\n",
            "200/391 [==============>...............] - ETA: 47s - loss: 0.3696 - accuracy: 0.5469 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-kF4EbtbBZ23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f01d733d-9ba7-4aad-c142-658c738d7c24"
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "x_test, y_test = dset.test_data[:]\n",
        "eval_model(model, x_test, y_test)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 342us/step\n",
            "Test loss: 0.507706770992279\n",
            "Test accuracy: 0.9033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CD410iQTbDUr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "save(model, history, 'res-net-28-2-1hr-dropout-IS')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XjUq7hi9BuEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "43635915-af3f-4a7f-afc5-dc55aae1ebd4"
      },
      "cell_type": "code",
      "source": [
        "# Load model and draw plots \n",
        "path = \"gdrive/My Drive/\"\n",
        "file_name = \"res-net-28-2-1hr-dropout-IS\"\n",
        "model = load_model(path + file_name + \".h5\")\n",
        "\n",
        "# Display Saved plots\n",
        "listOfImageNames = [path + file_name + \"-acc.png\",\n",
        "                    path + file_name + \"-loss.png\"]\n",
        "\n",
        "for imageName in listOfImageNames:\n",
        "    display(Image(filename=imageName))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-00d71c32d19b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gdrive/My Drive/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"res-net-28-2-1hr-dropout-IS\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Display Saved plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(f, custom_objects, compile)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    456\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 145\u001b[0;31m                                         list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m             \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# Nodes that cannot yet be processed (if the inbound node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m             layer = deserialize_layer(layer_data,\n\u001b[0;32m-> 1008\u001b[0;31m                                       custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m   1009\u001b[0m             \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 138\u001b[0;31m                                  ': ' + class_name)\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mcustom_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_objects\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown layer: LayerNormalization"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "12DajCB7Ge-R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D_YmyOmlbDtk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Wide ResNet 28-2 with 0.3 dropout and max time of 1 hr (without IS)"
      ]
    },
    {
      "metadata": {
        "id": "vvgp94svZJc4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "args = Args(depth = 28, width = 2, presample = 3.0, batch_size = 128, time_budget = 1, dropout = 0.3, useIS = False)\n",
        "model, history = build_wide_res(args, dset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7_kohQ8BbS8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save model and Eval\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NDyaylGBbaDR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Wide ResNet 28-2 without dropout and max time of 1 hr (with IS)"
      ]
    },
    {
      "metadata": {
        "id": "VhjPFRsPbaQp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "args = Args(depth = 28, width = 2, presample = 3.0, batch_size = 128, time_budget = 1, dropout = 0, useIS = True)\n",
        "model, history = build_wide_res(args, dset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Oa9fa6EbpPs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save model and Eval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BERLjEWkbpbn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Wide ResNet 28-2 without dropout and max time of 1 hr (without IS)"
      ]
    },
    {
      "metadata": {
        "id": "bqEqQuw9cEqN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "args = Args(depth = 28, width = 2, presample = 3.0, batch_size = 128, time_budget = 1, dropout = 0, useIS = False)\n",
        "model, history = build_wide_res(args, dset)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}